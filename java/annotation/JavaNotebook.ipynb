{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7PyAg+Lt7Zt7kRAyPuKgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alberwan/spark-nlp-workshop/blob/master/java/annotation/JavaNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMIrZTwR8Kyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "e56466eb-a372-4734-9472-d3380ccac675"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.5.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 63kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=1812f9cc2dc8d4b91e6bfc54b1f22c36f3316e7131cfc4424bd94c985fff2ce3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/b4/db653f8080a446de8ce981b262d85c85c61de7e920930726da0d1c6b4c65/spark_nlp-2.5.1-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvKhBTeGAGXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "11efa27a-53d7-4750-d43e-3705f26e4af6"
      },
      "source": [
        "#package EDG.SparkNLP.com;\n",
        "\n",
        "import com.johnsnowlabs.nlp.DocumentAssembler;\n",
        "import com.johnsnowlabs.nlp.EmbeddingsFinisher;\n",
        "import com.johnsnowlabs.nlp.LightPipeline;\n",
        "import com.johnsnowlabs.nlp.annotators.LemmatizerModel;\n",
        "import com.johnsnowlabs.nlp.annotators.Tokenizer;\n",
        "#import com.johnsnowlabs.nlp.embeddings.*; \n",
        "import com.johnsnowlabs.nlp.embeddings.EmbeddingsHelper;\n",
        "#import com.johnsnowlabs.nlp.embeddings.ClusterWordEmbeddings;\n",
        "import com.johnsnowlabs.nlp.SparkNLP;\n",
        "import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline;\n",
        "import org.apache.spark.ml.Pipeline;\n",
        "import org.apache.spark.ml.PipelineModel;\n",
        "import org.apache.spark.ml.PipelineStage;\n",
        "import org.apache.spark.sql.Dataset;\n",
        "import org.apache.spark.sql.Encoders;\n",
        "import org.apache.spark.sql.Row;\n",
        "import org.apache.spark.sql.SparkSession;\n",
        "\n",
        "import java.util.LinkedList;\n",
        "\n",
        "public class SparkNLPAnnotation {\n",
        "\n",
        "\tpublic static void main(String[] args) {\n",
        "\t\t// TODO Auto-generated method stub\n",
        "\t\tDocumentAssembler document = new DocumentAssembler();\n",
        "        document.setInputCol(\"text\");\n",
        "        document.setOutputCol(\"document\");\n",
        "        document.setCleanupMode(\"disabled\");\n",
        "\n",
        "        Tokenizer tokenizer = new Tokenizer();\n",
        "        tokenizer.setInputCols(new String[] {\"document\"});\n",
        "        tokenizer.setOutputCol(\"token\");\n",
        "\n",
        "        Pipeline pipeline = new Pipeline();\n",
        "        pipeline.setStages(new PipelineStage[] {document, tokenizer});\n",
        "\n",
        "        SparkSession spark = com.johnsnowlabs.nlp.SparkNLP.start(false, false);\n",
        "\n",
        "        LinkedList<String> text = new java.util.LinkedList<String>();\n",
        "\n",
        "        text.add(\"Peter is a very good person\");\n",
        "\n",
        "        Dataset<Row> data = spark.createDataset(text, Encoders.STRING()).toDF(\"text\");\n",
        "\n",
        "        PipelineModel pipelineModel = pipeline.fit(data);\n",
        "\n",
        "        Dataset<Row> transformed = pipelineModel.transform(data);\n",
        "        transformed.show();\n",
        "\n",
        "        /*\n",
        "         * Do Spark-NLP pretrained pipelines only work on linux systems?\n",
        "         * https://stackoverflow.com/questions/57610129/do-spark-nlp-pretrained-pipelines-only-work-on-linux-systems\n",
        "         * \n",
        "         */\n",
        "        PretrainedPipeline pretrained = new PretrainedPipeline(\"explain_document_dl\");\n",
        "        //PretrainedPipeline pretrained = new PretrainedPipeline(\"explain_document_dl_noncontrib\");\n",
        "        pretrained.transform(data).show();\n",
        "\n",
        "        LemmatizerModel lemmatizer = (LemmatizerModel) LemmatizerModel.pretrained(\"lemma_antbnc\");\n",
        "        lemmatizer.setInputCols(new String[] {\"token\"});\n",
        "        lemmatizer.setOutputCol(\"lemma\");\n",
        "\n",
        "        lemmatizer.transform(transformed).show();\n",
        "\n",
        "        LightPipeline lightPipeline = new LightPipeline(pipelineModel, true);\n",
        "\n",
        "        java.util.Map<String, java.util.List<String>> result = lightPipeline.annotateJava(\"Peter is a very good person.\");\n",
        "\n",
        "        System.out.println(result.get(\"token\"));\n",
        "\n",
        "        java.util.ArrayList<String> list = new java.util.ArrayList<String>();\n",
        "        list.add(\"Peter is a good person.\");\n",
        "        list.add(\"Roy lives in Germany.\");\n",
        "\n",
        "        System.out.println(lightPipeline.annotateJava(list));\n",
        "        \n",
        "        //EmbeddingsHelper.load(\"./random_embeddings_dim4.txt\",spark,\"TEXT\",\"random\",4,false);\n",
        "\n",
        "        System.out.println(\"\\nFinished testing Spark NLP on JAVA\");\n",
        "\t}\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-5294f86e90b3>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    public class SparkNLPAnnotation {\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}