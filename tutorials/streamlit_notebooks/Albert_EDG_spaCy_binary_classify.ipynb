{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Albert_EDG_spaCy_binary_classify.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXX9O2QSoL1dZmUmwQRLLc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alberwan/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/Albert_EDG_spaCy_binary_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rx4LEOJVeT3",
        "colab_type": "text"
      },
      "source": [
        "'''\n",
        "Text Classification with SpaCy\n",
        "\n",
        "Examples include spam detection, sentiment analysis, and tagging customer queries.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCxj7UevVrc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia8tl4HWV3po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "1. load data using pandas\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Loading the training data\n",
        "# Yes is the label for non-spam messages\n",
        "print(\"Please be patient, spaCy is training your model...\")\n",
        "spam = pd.read_csv('/content/spaCy_data/train_EDG.csv')\n",
        "# spam = pd.read_csv(os.path.dirname(__file__) + '\\\\' + 'train_EDG.csv')\n",
        "#print(spam.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNXU107bXi9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "b64bfdc1-ef3b-4805-8374-bca1657a562a"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.48.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.24.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6sRt1VcXfQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "2. Building a Bag of Words [bow] model\n",
        "'''\n",
        "# Create an empty model\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
        "textcat = nlp.create_pipe(\n",
        "    \"textcat\",\n",
        "    config={\n",
        "        \"exclusive_classes\": True,\n",
        "        # Since the classes are either ham(yes) or spam(no), we set \"exclusive_classes\" to True\n",
        "        \"architecture\": \"bow\"})\n",
        "\n",
        "# Add the TextCategorizer to the empty model. TextCategorizer is a spaCy pipe\n",
        "nlp.add_pipe(textcat)\n",
        "\n",
        "# Add labels to text classifier\n",
        "textcat.add_label(\"Yes\")\n",
        "textcat.add_label(\"No\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnM0MiEYr8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f8395a91-5d8c-495b-e37a-56f48a7579c6"
      },
      "source": [
        "'''\n",
        "3. Training a Text Categorizer Model\n",
        "'''\n",
        "train_texts = spam['text'].values\n",
        "train_labels = [{'cats': {'Yes': label == 'Yes',\n",
        "                          'No': label == 'No'}}\n",
        "                for label in spam['label']]\n",
        "\n",
        "train_data = list(zip(train_texts, train_labels))\n",
        "print(train_data[:3])\n",
        "\n",
        "'''\n",
        "3.1 Train the model\n",
        "    1. create an optimizer using nlp.begin_training(), spaCy uses this optimizer to update the model\n",
        "    2. in general it's more efficient to train models in small batches. spaCy provides the minibatch() function\n",
        "    3. the minibatches are split into texts and labels\n",
        "    4. nlp.update() to update the model's parameters.\n",
        "    Note: This is just one training loop (or epoch) through the data. The model will typically need multiple epochs.\n",
        "'''\n",
        "from spacy.util import minibatch\n",
        "\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "# Create the batch generator with batch size = 8\n",
        "batches = minibatch(train_data, size=8)\n",
        "# Iterate through minibatches\n",
        "for batch in batches:\n",
        "    # Each batch is a list of (text, label) but we need to\n",
        "    # send separate lists for texts and labels to update().\n",
        "    # This is a quick way to split a list of tuples into lists\n",
        "    texts, labels = zip(*batch)\n",
        "    nlp.update(texts, labels, sgd=optimizer)\n",
        "\n",
        "'''\n",
        "3.2 Use another loop for more epochs, and optionally re-shuffle the training data at the begining of each loop.\n",
        "'''\n",
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "losses = {}\n",
        "for epoch in range(10):\n",
        "    random.shuffle(train_data)\n",
        "    # Create the batch generator with batch size = 8\n",
        "    batches = minibatch(train_data, size=8)\n",
        "    # Iterate through minibatches\n",
        "    for batch in batches:\n",
        "        # Each batch is a list of (text, label) but we need to\n",
        "        # send separate lists for texts and labels to update().\n",
        "        # This is a quick way to split a list of tuples into lists\n",
        "        texts, labels = zip(*batch)\n",
        "        nlp.update(texts, labels, sgd=optimizer, losses=losses)\n",
        "    print(losses)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', {'cats': {'Yes': True, 'No': False}}), ('Ok lar... Joking wif u oni...', {'cats': {'Yes': True, 'No': False}}), (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", {'cats': {'Yes': False, 'No': True}})]\n",
            "{'textcat': 0.4318767588152923}\n",
            "{'textcat': 0.6474659060055785}\n",
            "{'textcat': 0.7841756387413232}\n",
            "{'textcat': 0.8715840899517864}\n",
            "{'textcat': 0.9279798743263192}\n",
            "{'textcat': 0.96545068234607}\n",
            "{'textcat': 0.9938352181410954}\n",
            "{'textcat': 1.012665496608121}\n",
            "{'textcat': 1.0274278897326723}\n",
            "{'textcat': 1.0377139946552003}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzopXk4yZVqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "86e0da13-aa58-419d-f234-aded5789c232"
      },
      "source": [
        "'''\n",
        "4. Making Predictions\n",
        "    Now that you have a trained model, you can make predictions with the predict() method. \n",
        "    The input text needs to be tokenized with nlp.tokenizer. \n",
        "    Then you pass the tokens to the predict method which returns scores. \n",
        "    The scores are the probability the input text belongs to the classes.\n",
        "'''\n",
        "while True:\n",
        "    texts = []\n",
        "    text1 = input(\"Input your text to predict:\")\n",
        "    texts.append(text1)\n",
        "\n",
        "    # texts = [\"Are you ready for the tea party????? It's gonna be wild\",\n",
        "    #          \"URGENT Reply to this message for GUARANTEED FREE TEA\"]\n",
        "    docs = [nlp.tokenizer(text) for text in texts]\n",
        "\n",
        "    # Use textcat to get the scores for each doc\n",
        "    textcat = nlp.get_pipe('textcat')\n",
        "    scores, _ = textcat.predict(docs)\n",
        "\n",
        "    # [[9.9994671e-01 5.3249827e-05]  --> probability belongs to \"ham\"is 9.9994671e-01, probability belongs to \"spam\"is 5.3249827e-05, so it is \"ham\"\n",
        "    #  [1.1798984e-02 9.8820102e-01]]\n",
        "    print(scores)\n",
        "\n",
        "    # From the scores, find the label with the highest score/probability\n",
        "    predicted_labels = scores.argmax(axis=1)  # get the index of the highest probability with scores.argmax\n",
        "    print(\"The predicted text \" +\"[\" + text1 + \"]\" + \" is \" +\n",
        "          str([textcat.labels[label] for label in predicted_labels]))\n",
        "\n",
        "    if input(\"Do you want to continue [y/n]\") != 'y':\n",
        "        break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input your text to predict:Are you ready for the tea party????? It's gonna be wild\n",
            "[[9.9994385e-01 5.6197885e-05]]\n",
            "The predicted text [Are you ready for the tea party????? It's gonna be wild] is ['Yes']\n",
            "Do you want to continue [y/n]y\n",
            "Input your text to predict:URGENT Reply to this message for GUARANTEED FREE TEA\n",
            "[[0.01154125 0.9884588 ]]\n",
            "The predicted text [URGENT Reply to this message for GUARANTEED FREE TEA] is ['No']\n",
            "Do you want to continue [y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}